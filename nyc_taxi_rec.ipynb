{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pyspark in c:\\users\\lenovo\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (3.3.2)\n",
      "Requirement already satisfied: py4j==0.10.9.5 in c:\\users\\lenovo\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from pyspark) (0.10.9.5)\n",
      "Collecting findspark\n",
      "  Downloading findspark-2.0.1-py2.py3-none-any.whl (4.4 kB)\n",
      "Installing collected packages: findspark\n",
      "Successfully installed findspark-2.0.1\n"
     ]
    }
   ],
   "source": [
    "!pip install pyspark\n",
    "!pip install findspark\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init()\n",
    "import pyspark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql.functions import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder \\\n",
    "    .master(\"local[*]\") \\\n",
    "    .appName('test') \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- VendorID: long (nullable = true)\n",
      " |-- tpep_pickup_datetime: timestamp (nullable = true)\n",
      " |-- tpep_dropoff_datetime: timestamp (nullable = true)\n",
      " |-- passenger_count: double (nullable = true)\n",
      " |-- trip_distance: double (nullable = true)\n",
      " |-- RatecodeID: double (nullable = true)\n",
      " |-- store_and_fwd_flag: string (nullable = true)\n",
      " |-- PULocationID: long (nullable = true)\n",
      " |-- DOLocationID: long (nullable = true)\n",
      " |-- payment_type: long (nullable = true)\n",
      " |-- fare_amount: double (nullable = true)\n",
      " |-- extra: double (nullable = true)\n",
      " |-- mta_tax: double (nullable = true)\n",
      " |-- tip_amount: double (nullable = true)\n",
      " |-- tolls_amount: double (nullable = true)\n",
      " |-- improvement_surcharge: double (nullable = true)\n",
      " |-- total_amount: double (nullable = true)\n",
      " |-- congestion_surcharge: double (nullable = true)\n",
      " |-- airport_fee: double (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = spark.read.parquet(\"yellow_tripdata_2021-02.parquet\")\n",
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+--------------------+---------------------+---------------+-------------+----------+------------------+------------+------------+------------+-----------+-----+-------+----------+------------+---------------------+------------+--------------------+-----------+\n",
      "|VendorID|tpep_pickup_datetime|tpep_dropoff_datetime|passenger_count|trip_distance|RatecodeID|store_and_fwd_flag|PULocationID|DOLocationID|payment_type|fare_amount|extra|mta_tax|tip_amount|tolls_amount|improvement_surcharge|total_amount|congestion_surcharge|airport_fee|\n",
      "+--------+--------------------+---------------------+---------------+-------------+----------+------------------+------------+------------+------------+-----------+-----+-------+----------+------------+---------------------+------------+--------------------+-----------+\n",
      "|       1| 2021-02-01 07:40:47|  2021-02-01 07:48:28|            1.0|          2.3|       1.0|                 N|         141|         226|           2|        8.5|  3.0|    0.5|       0.0|         0.0|                  0.3|        12.3|                 2.5|       null|\n",
      "|       1| 2021-02-01 07:07:44|  2021-02-01 07:20:31|            1.0|          1.6|       1.0|                 N|          43|         263|           2|        9.5|  3.0|    0.5|       0.0|         0.0|                  0.3|        13.3|                 0.0|       null|\n",
      "|       1| 2021-02-01 07:59:36|  2021-02-01 08:24:13|            1.0|          5.3|       1.0|                 N|         114|         263|           2|       19.0|  3.0|    0.5|       0.0|         0.0|                  0.3|        22.8|                 2.5|       null|\n",
      "+--------+--------------------+---------------------+---------------+-------------+----------+------------------+------------+------------+------------+-----------+-----+-------+----------+------------+---------------------+------------+--------------------+-----------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show(3)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Total Trip on Feb 15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\LENOVO\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pyspark\\sql\\dataframe.py:229: FutureWarning: Deprecated in 2.0, use createOrReplaceTempView instead.\n",
      "  warnings.warn(\"Deprecated in 2.0, use createOrReplaceTempView instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-------------------+-------------------+---------------+-------------+----------+------------------+------------+------------+------------+-----------+-----+-------+----------+------------+---------------------+------------+--------------------+-----------+\n",
      "|VendorID|          pickup_dt|         dropoff_dt|passenger_count|trip_distance|RatecodeID|store_and_fwd_flag|PULocationID|DOLocationID|payment_type|fare_amount|extra|mta_tax|tip_amount|tolls_amount|improvement_surcharge|total_amount|congestion_surcharge|airport_fee|\n",
      "+--------+-------------------+-------------------+---------------+-------------+----------+------------------+------------+------------+------------+-----------+-----+-------+----------+------------+---------------------+------------+--------------------+-----------+\n",
      "|       1|2021-02-01 07:40:47|2021-02-01 07:48:28|            1.0|          2.3|       1.0|                 N|         141|         226|           2|        8.5|  3.0|    0.5|       0.0|         0.0|                  0.3|        12.3|                 2.5|       null|\n",
      "+--------+-------------------+-------------------+---------------+-------------+----------+------------------+------------+------------+------------+-----------+-----+-------+----------+------------+---------------------+------------+--------------------+-----------+\n",
      "only showing top 1 row\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = df \\\n",
    "    .withColumnRenamed('tpep_pickup_datetime', 'pickup_dt') \\\n",
    "    .withColumnRenamed('tpep_dropoff_datetime', 'dropoff_dt')\n",
    "\n",
    "df.registerTempTable('nytaxi_tab')\n",
    "df.show(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------+\n",
      "|total_trip_feb15|\n",
      "+----------------+\n",
      "|           43686|\n",
      "+----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "total_trip_feb15 = spark.sql(\"\"\" \n",
    "\n",
    "    SELECT COUNT(pickup_dt) AS total_trip_feb15\n",
    "    FROM nytaxi_tab\n",
    "    WHERE pickup_dt >= '2021-02-15 00:00:00' AND pickup_dt < '2021-02-16 00:00:00'\n",
    "\n",
    "\"\"\")\n",
    "\n",
    "total_trip_feb15.show(1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Longest Trip per Day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.createOrReplaceTempView('data_view')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+------------+\n",
      "| pickup_dt|longest_trip|\n",
      "+----------+------------+\n",
      "|2021-02-16|   221188.25|\n",
      "|2021-02-20|   188054.03|\n",
      "|2021-02-08|   186617.92|\n",
      "|2021-02-07|   186510.67|\n",
      "|2021-02-03|   186079.73|\n",
      "+----------+------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "longesttrip_perday = df.withColumn(\"pickup_dt\" , to_date(df['pickup_dt']))\\\n",
    "                      .select(['pickup_dt','trip_distance'])\\\n",
    "                      .where(\"pickup_dt >= '2021-02-01' \")\\\n",
    "                      .groupby(F.col('pickup_dt')).agg(F.max('trip_distance').alias('longest_trip')).sort(desc(\"longest_trip\"))\n",
    "longesttrip_perday.show(5)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Top 5 most frequent dispatching_base_num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- hvfhs_license_num: string (nullable = true)\n",
      " |-- dispatching_base_num: string (nullable = true)\n",
      " |-- originating_base_num: string (nullable = true)\n",
      " |-- request_datetime: timestamp (nullable = true)\n",
      " |-- on_scene_datetime: timestamp (nullable = true)\n",
      " |-- pickup_datetime: timestamp (nullable = true)\n",
      " |-- dropoff_datetime: timestamp (nullable = true)\n",
      " |-- PULocationID: long (nullable = true)\n",
      " |-- DOLocationID: long (nullable = true)\n",
      " |-- trip_miles: double (nullable = true)\n",
      " |-- trip_time: long (nullable = true)\n",
      " |-- base_passenger_fare: double (nullable = true)\n",
      " |-- tolls: double (nullable = true)\n",
      " |-- bcf: double (nullable = true)\n",
      " |-- sales_tax: double (nullable = true)\n",
      " |-- congestion_surcharge: double (nullable = true)\n",
      " |-- airport_fee: double (nullable = true)\n",
      " |-- tips: double (nullable = true)\n",
      " |-- driver_pay: double (nullable = true)\n",
      " |-- shared_request_flag: string (nullable = true)\n",
      " |-- shared_match_flag: string (nullable = true)\n",
      " |-- access_a_ride_flag: string (nullable = true)\n",
      " |-- wav_request_flag: string (nullable = true)\n",
      " |-- wav_match_flag: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_1 = spark.read.parquet(\"fhvhv_tripdata_2021-02.parquet\", header=True, inferSchema=True)\n",
    "df_1.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+--------------------+--------------------+-------------------+-------------------+-------------------+-------------------+------------+------------+----------+---------+-------------------+-----+----+---------+--------------------+-----------+----+----------+-------------------+-----------------+------------------+----------------+--------------+\n",
      "|hvfhs_license_num|dispatching_base_num|originating_base_num|   request_datetime|  on_scene_datetime|    pickup_datetime|   dropoff_datetime|PULocationID|DOLocationID|trip_miles|trip_time|base_passenger_fare|tolls| bcf|sales_tax|congestion_surcharge|airport_fee|tips|driver_pay|shared_request_flag|shared_match_flag|access_a_ride_flag|wav_request_flag|wav_match_flag|\n",
      "+-----------------+--------------------+--------------------+-------------------+-------------------+-------------------+-------------------+------------+------------+----------+---------+-------------------+-----+----+---------+--------------------+-----------+----+----------+-------------------+-----------------+------------------+----------------+--------------+\n",
      "|           HV0003|              B02764|              B02764|2021-02-01 06:59:00|2021-02-01 07:10:19|2021-02-01 07:10:40|2021-02-01 07:21:09|          35|          39|      2.06|      629|              17.14|  0.0|0.51|     1.52|                 0.0|       null| 0.0|      9.79|                  N|                N|                  |               N|             N|\n",
      "+-----------------+--------------------+--------------------+-------------------+-------------------+-------------------+-------------------+------------+------------+----------+---------+-------------------+-----+----+---------+--------------------+-----------+----+----------+-------------------+-----------------+------------------+----------------+--------------+\n",
      "only showing top 1 row\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_1.show(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-------+\n",
      "|dispatching_base_num|  count|\n",
      "+--------------------+-------+\n",
      "|              B02510|3233664|\n",
      "|              B02764| 965568|\n",
      "|              B02872| 882689|\n",
      "|              B02875| 685390|\n",
      "|              B02765| 559768|\n",
      "+--------------------+-------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df1_top5 = df_1.groupBy(\"dispatching_base_num\").count() \\\n",
    "                    .orderBy(F.col('count').desc())\n",
    "\n",
    "df1_top5.show(5)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Top 5 most common location pairs (PULocationID and DOLocationID)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+------------+-----+\n",
      "|PUlocationID|DOlocationID|count|\n",
      "+------------+------------+-----+\n",
      "|         237|         236|11455|\n",
      "|         236|         237| 9901|\n",
      "|         236|         236| 8819|\n",
      "|         237|         237| 7324|\n",
      "|         264|         264| 5732|\n",
      "+------------+------------+-----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df2_top5 = df.where(\"PUlocationID IS NOT NULL AND DOlocationID IS NOT NULL\") \\\n",
    "                      .groupBy([\"PUlocationID\",'DOlocationID']) \\\n",
    "                      .count() \\\n",
    "                      .orderBy(F.col('count').desc())\n",
    "df2_top5.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+------------+-----+\n",
      "|PUlocationID|DOlocationID|count|\n",
      "+------------+------------+-----+\n",
      "|          76|          76|45041|\n",
      "|          26|          26|37329|\n",
      "|          39|          39|28026|\n",
      "|          61|          61|25976|\n",
      "|          14|          14|17934|\n",
      "+------------+------------+-----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "top5_location_pairs_fhv = df_1.where(\"PUlocationID IS NOT NULL AND DOlocationID IS NOT NULL\") \\\n",
    "                          .groupBy([\"PUlocationID\",'DOlocationID']) \\\n",
    "                          .count() \\\n",
    "                          .orderBy(F.col('count').desc())\n",
    "top5_location_pairs_fhv.show(5)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Write all result to Bigquery table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df_wiki_en_totals' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[32], line 5\u001b[0m\n\u001b[0;32m      2\u001b[0m bq_dataset \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mtask6_iykra\u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m      3\u001b[0m bq_table \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mnyc_taxi_rec\u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m----> 5\u001b[0m df_wiki_en_totals\u001b[39m.\u001b[39mwrite \\\n\u001b[0;32m      6\u001b[0m   \u001b[39m.\u001b[39mformat(\u001b[39m\"\u001b[39m\u001b[39mbigquery\u001b[39m\u001b[39m\"\u001b[39m) \\\n\u001b[0;32m      7\u001b[0m   \u001b[39m.\u001b[39moption(\u001b[39m\"\u001b[39m\u001b[39mtable\u001b[39m\u001b[39m\"\u001b[39m,\u001b[39m\"\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m.\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(bq_dataset, bq_table)) \\\n\u001b[0;32m      8\u001b[0m   \u001b[39m.\u001b[39moption(\u001b[39m\"\u001b[39m\u001b[39mtemporaryGcsBucket\u001b[39m\u001b[39m\"\u001b[39m, gcs_bucket) \\\n\u001b[0;32m      9\u001b[0m   \u001b[39m.\u001b[39mmode(\u001b[39m'\u001b[39m\u001b[39moverwrite\u001b[39m\u001b[39m'\u001b[39m) \\\n\u001b[0;32m     10\u001b[0m   \u001b[39m.\u001b[39msave()\n",
      "\u001b[1;31mNameError\u001b[0m: name 'df_wiki_en_totals' is not defined"
     ]
    }
   ],
   "source": [
    "gcs_bucket = 'data-fellowship-9'\n",
    "bq_dataset = 'task6_iykra'\n",
    "bq_table = 'nyc_taxi_rec'\n",
    "\n",
    "df_wiki_en_totals.write \\\n",
    "  .format(\"bigquery\") \\\n",
    "  .option(\"table\",\"{}.{}\".format(bq_dataset, bq_table)) \\\n",
    "  .option(\"temporaryGcsBucket\", gcs_bucket) \\\n",
    "  .mode('overwrite') \\\n",
    "  .save()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "a6320b9647c5e6533fdfebe9933a282ad93e2f9665a5a4cd202ca91bba410bf6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
